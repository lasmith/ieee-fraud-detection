{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IEEE Fraud Detection Using Catboost\n",
    "The below model is based on catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, f1_score, matthews_corrcoef\n",
    "import seaborn as sns\n",
    "\n",
    "import datetime, random, sys\n",
    "\n",
    "import hyperopt\n",
    "from numpy.random import RandomState\n",
    "\n",
    "sys.path.append(\"../src/python\")\n",
    "from data.utils import get_lbo_pools, gen_seeds, get_catboost_pools\n",
    "\n",
    "from data.preprocessor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_columns = None\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "DATA_DIR='../data/raw'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lsmith/anaconda3/envs/ieee-fraud-detection/lib/python3.7/site-packages/pandas/core/series.py:853: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/lsmith/anaconda3/envs/ieee-fraud-detection/lib/python3.7/site-packages/pandas/core/series.py:853: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = preprocess(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LBO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and now create datasets using a \"leave block out (LBO)\"\" split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, X_valid, y_valid = get_lbo_pools(df_train)\n",
    "train_pool, validate_pool = get_catboost_pools(X, y, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets check the target split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Param Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_objective(params):\n",
    "    print('Params: '+str(params))\n",
    "    model = CatBoostClassifier(\n",
    "        l2_leaf_reg=int(params['l2_leaf_reg']),\n",
    "        learning_rate=params['learning_rate'],\n",
    "        loss_function=str(params['loss_function']),\n",
    "        iterations=500,\n",
    "        eval_metric=str(params['eval_metric']),\n",
    "        random_seed=42,\n",
    "        logging_level='Silent',\n",
    "        custom_metric=['F1','MCC'],\n",
    "        use_best_model=True,\n",
    "        #'early_stopping_rounds': 30,\n",
    "        od_type= 'Iter',\n",
    "        od_wait= 40,\n",
    "        depth=int(params['depth'])\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        train_pool,\n",
    "        eval_set=validate_pool    \n",
    "    );\n",
    "\n",
    "    # Get results and scores\n",
    "    preds = model.predict(X_valid)\n",
    "    acc_score = accuracy_score(y_valid, preds)\n",
    "    auc_score = roc_auc_score(y_valid, preds)\n",
    "    f1 = f1_score(y_valid, preds.round())\n",
    "    mcc = matthews_corrcoef(y_valid, preds.round())\n",
    "    print(\"Accuracy score: %s, AUC: %s, F1: %s, MCC: %s\" % (acc_score, auc_score,f1, mcc))\n",
    "    \n",
    "    return 1 - auc_score # as hyperopt minimises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_space = {\n",
    "    'l2_leaf_reg': hyperopt.hp.qloguniform('l2_leaf_reg', 0, 2, 1),\n",
    "    'learning_rate': hyperopt.hp.uniform('learning_rate', 1e-3, 5e-1),\n",
    "    #'eval_metric': hyperopt.hp.choice('eval_metric',['F1', 'MCC', 'Accuracy'])\n",
    "    'loss_function': hyperopt.hp.choice('loss_function',['CrossEntropy','Logloss']),\n",
    "    'eval_metric': hyperopt.hp.choice('eval_metric',['MCC','AUC']),\n",
    "    'depth': hyperopt.hp.quniform('depth', 4,10,1)\n",
    "    \n",
    "}\n",
    "\n",
    "trials = hyperopt.Trials()\n",
    "\n",
    "best = hyperopt.fmin(\n",
    "    hyperopt_objective,\n",
    "    space=params_space,\n",
    "    algo=hyperopt.tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=trials,\n",
    "    rstate=RandomState(123)\n",
    ")\n",
    "\n",
    "print(best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ieee-fraud)",
   "language": "python",
   "name": "iee-fraud"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
